# 201700301166 å°¹æˆæ—

import csv
import random
from math import log
import numpy as np

dict_iris = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}
dict_siri = {0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}


class treenode:
    def __init__(self, FenLei, FenLeiZhi, YeziPanDuan, node_id):
        self.FenLei = FenLei
        self.FenLeiZhi = FenLeiZhi
        self.YeziPanDuan = YeziPanDuan
        self.fenleiindex = [0, 1, 2]
        self.node_id = node_id
        '''if int(YeziPanDuan) == -1:
            print("äº§ç”Ÿä¸­é—´èŠ‚ç‚¹{}ï¼Œä¸ºç¬¬{}ç‰¹å¾ï¼Œåˆ†ç±»å€¼ä¸º{}".format(node_id, FenLei, FenLeiZhi))
        else:
            print("äº§ç”Ÿå¶å­èŠ‚ç‚¹{}ï¼Œåˆ¤æ–­ç»“æœä¸º{}".format(node_id, dict_siri[YeziPanDuan]))'''
    def popfenlei(self, fenlei):
        ii = 0
        for i in self.fenleiindex:
            if int(i) == int(fenlei):
                self.fenleiindex.pop(ii)
                return
            ii = ii+1

# å»ºç«‹ç”¨æ¥å‚¨å­˜æˆ‘ä»¬çš„æ ‘èŠ‚ç‚¹çš„
nodes = []


# æ„å»ºä¸€ä¸ªæ ‘
def buildTree(dataset, node_id):
    if get_ent(dataset) != 0:
        fenlei, fenleizhi = get_fenleidian(dataset)
        trnode = treenode(fenlei, fenleizhi, -1, node_id)
        trnode.popfenlei(fenlei)
        nodes.append(trnode)
        datasmall, databig = divide(dataset, fenlei, fenleizhi)
        #print(get_ent(datasmall))
        #print(get_ent(databig))
        buildTree(datasmall, 2 * node_id)
        #print("hhhhhhhhhhhh{}".format(dataset[0][4]))
        buildTree(databig, 2 * node_id + 1)
    else:
        #print("hhhhhhhhhhhh{}".format(dataset[0][4]))
        if len(dataset) == 0:
            #print("ffff")
            return
        panduan = dataset[0][3]
        trnode = treenode(0, 0, panduan, node_id)
        nodes.append(trnode)


# æ„å»ºä¸€ä¸ªå°å°æ ‘
def buildTreeR(dataset, node_id, idd):
    if get_ent(dataset) != 0:
        fenlei, fenleizhi = get_fenleidianR(dataset, idd)
        trnode = treenode(fenlei, fenleizhi, -1, node_id)
        trnode.popfenlei(fenlei)
        nodes.append(trnode)
        datasmall, databig = divide(dataset, fenlei, fenleizhi)
        #print(get_ent(datasmall))
        #print(get_ent(databig))
        buildTree(datasmall, 2 * node_id)
        #print("hhhhhhhhhhhh{}".format(dataset[0][4]))
        buildTree(databig, 2 * node_id + 1)
    else:
        #print("hhhhhhhhhhhh{}".format(dataset[0][4]))
        if len(dataset) == 0:
            #print("ffff")
            return
        panduan = dataset[0][3]
        trnode = treenode(0, 0, panduan, node_id)
        nodes.append(trnode)



# åŠ è½½å‡½æ•°
def loadcsv(name):
    f = csv.reader(open(name, 'r'))
    dataset = list(f)
    return dataset


# æŠŠæ•°æ®æ•°å­—åŒ–
def digital(dataset):
    for i in range(len(dataset)):
        dataset[i][3] = dict_iris[dataset[i][3]]

# æŠŠç¬¬numä¸ªæ•°æ®è¿›è¡Œæ’åˆ—,å¹¶å–å‡ºå¯èƒ½çš„åˆ†å‰²ç‚¹
def get_mid(dataset,num):
    l1 = []
    l2 = []
    for i in range(len(dataset)):
        l1.append(dataset[i][num])
    l1 = list(set(l1))
    l1.sort()
    for i in range(len(l1)-1):
        l2.append(((float)(l1[i])+(float)(l1[i+1]))/2)
    return l2


# åˆ†å‰²å‡½æ•°
def randDivision(dataset , trainSize):
    copy = list(dataset)
    train = []
    while len(train)<trainSize:
        index = random.randrange(len(copy))
        train.append(copy.pop(index))
    return [train, copy]


'''
è®¡ç®—ä¿¡æ¯ç†µå’Œä¿¡æ¯å¢ç›Š
'''


# åˆ’åˆ†æ•°æ®é›†æ–¹ä¾¿è®¡ç®—æ¡ä»¶ä¿¡æ¯ç†µ
def divide(dataset, index, dnum):
    dataset2 = list(dataset)
    dataset1 = []
    ii  = 0
    for i in dataset:
        if (float)(i[index])<(float)(dnum):
            dataset1.append(i)
            dataset2.pop(ii)
            ii = ii-1
        ii = ii+1
    return [dataset1, dataset2]


# è®¡ç®—ä¿¡æ¯ç†µ
def getP(dataset,num):
    p = 0.0
    a = len(dataset)
    if a == 0:
        return 0
    b = 0
    for i in dataset:
        if i[3] == num:
            b = b+1
    p = b/a
    #print(p)
    return p


def get_ent(dataset):
    p = []
    ent = 0.0
    for i in range(3):
        pp = getP(dataset, i)
        p.append(pp)
    for i in p:
        if i != 0:
            ent = ent - i*log(i, 2)
    return ent


# è®¡ç®—ä¿¡æ¯å¢ç›Š
def get_gain(dataset, index, dnum):
    entD = get_ent(dataset)
    data1, data2 = divide(dataset, index, dnum)
    a1 = 0.0
    a2 = 0.0
    gain = 0.0
    '''print("dataçš„ç†µ{}".format(entD))
    print("data1çš„ç†µ{}".format(get_ent(data1)))
    print("data2çš„ç†µ{}".format(get_ent(data2)))'''
    a2 = len(data2)/len(dataset)
    a1 = len(data1)/len(dataset)
    gain = entD - a1*get_ent(data1) - a2*get_ent(data2)
    return gain


# å¾—åˆ°å•ä¸ªç‰¹å¾æœ€é«˜çš„ä¿¡æ¯å¢ç›Šæ‰€åœ¨çš„åˆ†ç±»ç‚¹
def get_maxgain(dataset, index):
    max = -10000
    iii = 0
    dnums = get_mid(dataset, index)
    for i in dnums:
        gg = get_gain(dataset, index, i)
        if gg>=max:
            max = gg
            iii = i
    return iii


# å¤šä¸ªç‰¹å¾ä¸­é€‰æ‹©ä¸€ä¸ªåˆ†ç±»ç‚¹
'''
è¾“å…¥ï¼šæ•°æ®é›†ï¼Œå„ä¸ªç‰¹å¾çš„æœ€ä½³åˆ†ç±»ç‚¹
è¾“å‡ºï¼šæ’åºlist
'''
def get_maxtezheng(dataset,node):
    max = 0
    max_i = 0
    max_list = []
    for i in range(len(node)):
        a = get_gain(dataset, i, node[i])
        max_list.append(a)
        if max<a:
            max_i = i
            max = a
    return [max_list, max_i]

def get_maxtezhengR(dataset,node,idd):
    max = 0
    max_i = 0
    max_list = []
    for i in range(len(node)):
        if i==idd:
            print(i)
        else:
            a = get_gain(dataset, i, node[i])
            max_list.append(a)
            if max<a:
                max_i = i
                max = a
    return [max_list, max_i]


def get_fenleidianR(dataset, idd):
    divide_node = []
    for tezheng in range(3):

        divide_node.append(get_maxgain(dataset, tezheng))
        #print("*********************")
        #print("æ‰€ä»¥åº”è¯¥ç¬¬{}ä¸ªç‰¹å¾é€‰æ‹©{}ä½œä¸ºåˆ†å‰²ç‚¹".format(tezheng, get_maxgain(dataset, tezheng)))
        #print("*********************")
    max_list, max_i = get_maxtezhengR(trainSet, divide_node, idd)
    #print(max_i)
    #print(max_list)
    return [max_i, divide_node[max_i]]

def get_fenleidian(dataset):
    divide_node = []
    for tezheng in range(3):
        divide_node.append(get_maxgain(dataset, tezheng))
        #print("*********************")
        #print("æ‰€ä»¥åº”è¯¥ç¬¬{}ä¸ªç‰¹å¾é€‰æ‹©{}ä½œä¸ºåˆ†å‰²ç‚¹".format(tezheng, get_maxgain(dataset, tezheng)))
        #print("*********************")
    max_list, max_i = get_maxtezheng(trainSet, divide_node)
    #print(max_i)
    #print(max_list)
    return [max_i, divide_node[max_i]]


def find_(node_id):
    for node in range(len(nodes)):
        if nodes[node].node_id == node_id:
            return node+1
    return -1


votes = []

# éªŒè¯å‡½æ•°
def classify(dataset, nodes):
    corr = 0    # è®°å½•æ­£ç¡®çš„æ•°ç›®

    allof = len(dataset)    # æ€»æ•°
    for item in dataset:
        aa = 1
        #print(aa)
        nnn = nodes[aa-1]
        while int(nnn.YeziPanDuan) == int(-1):  # åœ¨ä¸»èŠ‚ç‚¹ä¹‹é—´é¨æ¸¸
            if float(item[int(nnn.FenLei)]) <= float(nnn.FenLeiZhi):
                aa = 2*aa
                #print("å·¦")
                nnn = nodes[find_(aa)-1]   # å·¦å­æ ‘
            else:
                #print("ğŸ‘‰")
                aa = 2*aa+1
                nnn = nodes[find_(aa)-1]     # å³å­æ ‘
        #print("æ ‘ç»“æœä¸º{}ï¼Œ å®é™…ä¸º{}".format(nnn.YeziPanDuan, item[4]))
        if nnn.YeziPanDuan == item[3]:  # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            #print("æ ‘ç»“æœä¸º{}ï¼Œ å®é™…ä¸º{}".format(nnn.YeziPanDuan, item[4]))
            corr = corr+1
        aa = 1
    bibi = 0.0
    bibi = corr/allof
    return bibi


def get_panduan(vote):
    kkk = [0, 0, 0]
    for i in vote:
        kkk[i] = kkk[i]+1
    max_index = kkk.index(max(kkk))
    # print(vote)
    return max_index


def use_vote(dataset):
    corr = 0
    fins = []
    for i in range(len(votes[0])):
        kkkk = []
        for vote in votes:
            kkkk.append(vote[i])
        fin = get_panduan(kkkk)
        fins.append(fin)
    for item in range(len(dataset)):
        if fins[item] == dataset[item][3]:  # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            #print("æ ‘ç»“æœä¸º{}ï¼Œ å®é™…ä¸º{}".format(fins[item], dataset[item][3]))
            corr = corr + 1
    allof = len(dataset)
    bibi = corr / allof
    return bibi


def vote(dataset, node):
    corr = 0  # è®°å½•æ­£ç¡®çš„æ•°ç›®
    vote = []
    allof = len(dataset)  # æ€»æ•°
    for item in dataset:
        aa = 1
        # print(aa)
        nnn = nodes[aa - 1]
        while int(nnn.YeziPanDuan) == int(-1):  # åœ¨ä¸»èŠ‚ç‚¹ä¹‹é—´é¨æ¸¸
            if float(item[int(nnn.FenLei)]) <= float(nnn.FenLeiZhi):
                aa = 2 * aa
                # print("å·¦")
                nnn = nodes[find_(aa) - 1]  # å·¦å­æ ‘
            else:
                # print("ğŸ‘‰")
                aa = 2 * aa + 1
                nnn = nodes[find_(aa) - 1]  # å³å­æ ‘
        # print("æ ‘ç»“æœä¸º{}ï¼Œ å®é™…ä¸º{}".format(nnn.YeziPanDuan, item[4]))
        vote.append(nnn.YeziPanDuan)
        if nnn.YeziPanDuan == item[3]:  # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            # print("æ ‘ç»“æœä¸º{}ï¼Œ å®é™…ä¸º{}".format(nnn.YeziPanDuan, item[4]))
            corr = corr + 1
        aa = 1
    bibi = 0.0
    #print(vote)
    votes.append(vote)
    bibi = corr / allof
    return bibi


# main function
if __name__=="__main__":
    noddds = [[], [], [], []]
    for i in range(4):
        name = "..\data\i{}.csv".format(i)
        print(name)
        dataset = loadcsv(name)
        digital(dataset)
        trainSet, testSet = randDivision(dataset, 100)
        #print(get_fenleidian(trainSet))
        #set1, set2 = divide(trainSet, 3, 0.8)
        #tr = treenode(0,0,0,0)
        buildTree(trainSet, 1)
        noddds[i] = nodes
        #print(nodes)
        a = vote(dataset, noddds[i])
        print("éªŒè¯å¾—çŸ¥ï¼Œæ­£ç¡®ç‡ä¸º{}%".format(a * 100))
        nodes = []
    a = use_vote(dataset)
    print("éªŒè¯å¾—çŸ¥æŠ•ç¥¨åï¼Œæ­£ç¡®ç‡ä¸º{}%".format(a*100))
    #aaaaa = FiveFordCV(dataset, 150, 5)
    #print("ç»äº”æŠ˜äº¤å‰éªŒè¯åå¾—çŸ¥ï¼Œæ­£ç¡®ç‡ä¸º{}%".format(aaaaa*100))









